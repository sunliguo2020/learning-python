Scrapy内部提供了两个专门的Item Pipeline，用于下载文件和图片：

FilesPipeline

ImagesPipeline

用户使用时只需要通过item的一个特殊字段将要下载的文件图片的url传递给他们，他们会自动将文件或图片下载到本地，并将结果信息存入item的另一个特殊字段。

步骤1：在settings.py中启用FilesPipeline

```python
ITEM_PIPELINES = {
    'scrapy.pipelines.files.FilesPipeline': 1,   
}
```

步骤2：在settings.py中，使用FIlES_STORE指定文件下载目录

```python
FILES_STORE = 'examples_src'
```

步骤3：解析出一个url，赋给item的file_urls字段（item['file_urls'])。FilePipeline在处理每一项item时，会读取item['file_urls']，对其中每一个url进行下载

```python

class xxx(scrapy.Spider):
    def parse(self,response):
        item={}
        item['file_urls']=[]
      	for url in xxx:
            item['file_urls'] =.append(url)
	yield item        
```

|          | FilesPipeline                        | ImagesPipeline                       |
| -------- | ------------------------------------ | ------------------------------------ |
| 导入路径 | scrapy.pipelines.files.FilesPipeline | scrapy.pipeline.images.ImagePipeline |
| Item字段 | files_urls,files                     | image_urls,images                    |
| 下载目录 | FILES_STORE                          | IMAGES_STORE                         |

